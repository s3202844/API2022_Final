<!DOCTYPE html>
<html>

<link href="style.css" rel="stylesheet" type="text/css" />

<body>
    <div class="container">

        <head>
            <meta charset="utf-8">
            <title>API2022 Final</title>
            <link rel="shortcut icon" href="data/leidenuniv.ico">
        </head>

        <main class="main">
            <h1 class="title">Sheet Music Generation</h1>
            <!-- <h3 class="authorby">Fall 2022 API Final Project by:</h3> -->
            <h3 class="">Yuang Yuan, Haoran Yin, Pim Bax</h3>

            <div class="abstract">
                <div class="section">
                    <h1 class="sectiontitle">Abstract</h1>
                </div>
            </div>

            <div class="section">
                <h1 class="sectiontitle">Audio Separation</h1>
                <p class="paragraph"> (Bullshit content) Generally speaking, students will withdraw from
                    the membership, how should it be realized. Now, it is very, very important to solve the problem
                    of student union withdrawal. Therefore, after the above discussion, from this point of view,
                    Russell Baker once mentioned that even if a person has reached the top, he still has to strive
                    for self-improvement. This seems to answer my doubts. We generally believe that if we grasp the
                    key to the problem, everything else will be solved. From this point of view, I think, well, in
                    summary, everyone has to face these problems. When faced with this kind of problem, generally
                    speaking, students will withdraw from the club, what will happen if it happens, and what will
                    happen if it doesn't happen. From this point of view, however, even so, the emergence of the
                    student union withdrawal still represents a certain significance. Under such a difficult choice,
                    I thought about it and couldn't sleep or eat. We have to face a very embarrassing fact, that is.</p>
            </div>

            <div class="section">
                <h1 class="sectiontitle">Audio to MIDI</h1>

                <p class="paragraph">
                    MIDI (Musical Instrument Digital Interface) was proposed in the early 1980s to solve the
                    communication problem between electro-acoustic instruments. MIDI is the most extensive music
                    standard format in the arranger world, and it can be called "music notation that computers can
                    understand." It uses digital control signals of notes to record music <a href="#cite1">[1]</a>.
                </p>
                <p>
                    Considering the importance of this part, we chose a novel research,
                    <a href="https://basicpitch.spotify.com/" target="_blank">Basic Pitch</a>, as the basis of our
                    work <a href="#cite2">[2]</a>. This research was released in conjunction with Spotify's publication
                    at ICASSP 2022. It introduces a lightweight yet powerful Automatic Music Transcription (AMT)
                    model. To train our model, we use three datasets,
                    <a href="https://www.upf.edu/web/mtg/mtg-qbh" target="_blank">MTG-QBH</a>,
                    <a href="https://magenta.tensorflow.org/datasets/maestro" target="_blank">MAESTRO</a>, and
                    <a href="https://source-separation.github.io/tutorial/data/musdb18.html"
                        target="_blank">MUSDB18</a>. Here are some exciting transcription results for different
                    instruments (including vocals).
                </p>

                <div class="audiopreview">
                    <div>
                        <p class="paragraph">Vocals (from MUSDB18):</p>
                        <audio controls src="data/vocals.mp3">
                            Your browser does not support the
                            <code>audio</code> element.
                        </audio>
                    </div>
                    <div>
                        <p class="paragraph">MIDI Transcription:</p>
                        <audio controls src="data/vocals_pre.mp3">
                            Your browser does not support the
                            <code>audio</code> element.
                        </audio>
                    </div>
                </div>
                <div class="audiopreview">
                    <div>
                        <p class="paragraph">
                            <a href="#sheet" id="piano">Piano</a> (from MTG-QBH):
                        </p>
                        <audio controls src="data/piano.mp3">
                            Your browser does not support the
                            <code>audio</code> element.
                        </audio>
                    </div>
                    <div>
                        <p class="paragraph">
                            <a href="#sheet_pre" id="midi_trans">MIDI Transcription:</a>
                        </p>
                        <audio controls src="data/piano_pre.mp3">
                            Your browser does not support the
                            <code>audio</code> element.
                        </audio>
                    </div>
                </div>
                <div class="audiopreview">
                    <div>
                        <p class="paragraph">Guitar (from MAESTRO):</p>
                        <audio controls src="data/guitar.mp3">
                            Your browser does not support the
                            <code>audio</code> element.
                        </audio>
                    </div>
                    <div>
                        <p class="paragraph">MIDI Transcription:</p>
                        <audio controls src="data/guitar_pre.mp3">
                            Your browser does not support the
                            <code>audio</code> element.
                        </audio>
                    </div>
                </div>

                <p></p>

                <div class="imagewrapper">
                    <img src="data/basic_pitch.png" width="90%" />
                </div>
                <p align="center"><b>Figure</b> , Comparison of <i>Basic Pitch</i> and a recent, strong baseline model,
                    MI-AMT <a href="#cite3">[3]</a>. It uses a U-Net architecture with an attention mechanism and
                    outputs a note-activation posteriorgram with a total of over 20M parameters, trained on MAESTRO and
                    MusicNet. Average note event metrics on all test datasets for the baseline algorithm, proposed
                    method, and ablation experiments. The best score for each column is in bold. The shade of green
                    indicates how far a score is from the best score, with the worst scores in white. All non-underlined
                    results are statistically significantly different with <i>p</i> < 0.05 compared with NMP
                        (permetric/dataset) via a paired t-test. </p>

            </div>

            <div class="section">
                <h1>MIDI to Note Sheet</h1>

                <p class="paragraph"> To generate the sheet music, we used the Mingus library in Python to read the midi files.
                    This library is able to convert the midi files to an internal representation, which can then be converted to
                    a so-called 'LilyPad' string. This string will then be used by LilyPad, another library, to generate a PDF of
                    the sheet music.
                </p>
                <p class="paragraph">
                    When trying to read the midi files, we ran into some issues of Mingus not being able to interpret the specific
                    midi format as generated in the earlier steps. This means that we first had to make some changes to the midi output
                    of our previous steps, before we were able to interpret these midi files.
                </p>
                
                <p> Here are the sheets for 2 audio clips from last section, represents <i>Piano</i> and <i>MIDI
                        Transcription</i> respectively. </p>
                <p id="sheet">Sheet of ground truth(<a href="#piano">Piano</a>)</p>
                <div class="imagewrapper">
                    <img src="data/sheet.png" />
                </div>
                <p id="sheet_pre">Sheet of <a href="#midi_trans">MIDI transcription</a></p>
                <div class="imagewrapper">
                    <img src="data/sheet_pre.png" />
                </div>
            </div>


            <div class="section">
                <h1>References</h1>
                <ol>
                    <li class="listitem" id="cite1">
                        Rothstein, J. (1992). MIDI: A comprehensive introduction (Vol. 7). AR Editions, Inc..
                    </li>
                    <li class="listitem" id="cite2">
                        Bittner, R. M., Bosch, J. J., Rubinstein, D., Meseguer-Brocal, G., & Ewert, S. (2022, May). A
                        Lightweight Instrument-Agnostic Model for Polyphonic Note Transcription and Multipitch
                        Estimation. In ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal
                        Processing (ICASSP) (pp. 781-785). IEEE.
                    </li>
                    <li class="listitem" id="cite3">
                        Wu, Y. T., Chen, B., & Su, L. (2020). Multi-instrument automatic music transcription with
                        self-attention-based instance segmentation. IEEE/ACM Transactions on Audio, Speech, and Language
                        Processing, 28, 2796-2809.
                    </li>
                </ol>
            </div>
        </main>
    </div>
</body>

</html>
